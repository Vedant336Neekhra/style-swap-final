{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HL8V4vxgLMb"
      },
      "source": [
        "Used this - https://github.com/lucidrains/stylegan2-pytorch\n",
        "stylgan2 for training.\n",
        "\n",
        "The official NV labs one - https://github.com/NVlabs/stylegan2-ada-pytorch?tab=readme-ov-file require python 3.7, torch 1.8 to which we have to create a env or change python versions in colab(can do on local, but we have compute on colab so :) ) usr/bin which was a total nightmare(3 hrs wasted successfully)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2Qi92_4OVRm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stylegan2_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2swBqg4Ozz3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhm5s48GO29m",
        "outputId": "f5987ffc-5e2b-46e9-9e50-b84f1ddcc9fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: qubit64\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/rkuo2000/viton-dataset\n",
            "Downloading viton-dataset.zip to ./viton-dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 629M/629M [00:06<00:00, 100MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/rkuo2000/viton-dataset/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBU9PZ6OO-da",
        "outputId": "9de043df-6e6c-4b8e-cc67-23d574ad8ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pog2ugT5O6WD",
        "outputId": "5027dc49-1fd1-4f01-fa87-32a7737dae30"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "input_path = '/content/viton-dataset/ACGPN_TrainData/train_img'\n",
        "output_path = '/content/custom_dataset/resized_dataset'\n",
        "\n",
        "im_size = 256\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "for file in os.listdir(input_path):\n",
        "    file_path = os.path.join(input_path, file)\n",
        "\n",
        "    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        img = cv2.imread(file_path)\n",
        "\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (im_size, im_size))\n",
        "            print(f'Resized image shape: {img.shape}')\n",
        "\n",
        "            output_file_path = os.path.join(output_path, file)\n",
        "            cv2.imwrite(output_file_path, img)\n",
        "        else:\n",
        "            print(f'Error reading image: {file_path}')\n",
        "    else:\n",
        "        print(f'Skipping non-image file: {file_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXuFZUk2OeqT",
        "outputId": "5b6a0f74-beb5-4238-91ff-f9f540c6be58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "continuing from previous epoch - 0\n",
            "loading from version 1.8.10\n",
            "default</content/custom_dataset/resized_dataset>:   0% 0/150000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "default</content/custom_dataset/resized_dataset>:   0% 20/150000 [00:38<80:23:52,  1.93s/it]^C\n"
          ]
        }
      ],
      "source": [
        "# !stylegan2_pytorch --data /content/custom_dataset/resized_dataset\n",
        "!stylegan2_pytorch --data /content/custom_dataset/resized_dataset --results_dir /content/results --models_dir /content/model --network-capacity 256 --image-size 256 --batch-size 32 --gradient-accumulate-every 16 --multiple-gpus"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
